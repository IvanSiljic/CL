{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ovo pokrenuti ukoliko želite da se svi izrazi unutar ćelije ispišu\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# N-gramski jezični model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.lm.preprocessing import pad_both_ends, flatten, padded_everygram_pipeline\n",
    "from nltk.util import bigrams, ngrams\n",
    "from nltk.lm import MLE, Laplace, Vocabulary\n",
    "import nltk.lm as lm\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "text =  [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('a', 'b', 'c')],\n",
       " [('a', 'c', 'd'), ('c', 'd', 'c'), ('d', 'c', 'e'), ('c', 'e', 'f')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import bigrams, ngrams\n",
    "list(bigrams(text[0]))\n",
    "[list(ngrams(sent,n=3)) for sent in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'a', 'b', 'c', '</s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import pad_sequence\n",
    "list(pad_sequence(text[0],\n",
    "    pad_left=True,\n",
    "    left_pad_symbol=\"<s>\",\n",
    "    pad_right=True,\n",
    "    right_pad_symbol=\"</s>\",\n",
    "n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(pad_both_ends(text[0], n=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Za model nam  je potreban skup svih tokena kao vokabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import flatten\n",
    "vocab = list(flatten(pad_both_ends(sent, n=2) for sent in text))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]\n",
      "train [('<s>',), ('<s>', 'a'), ('a',), ('a', 'b'), ('b',), ('b', 'c'), ('c',), ('c', '</s>'), ('</s>',)]\n",
      "vocab ['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(2, text)\n",
    "#train = [list(ngrams(pad_both_ends(sent, n=2),2)) for sent in text]\n",
    "#vocab = list(flatten(pad_both_ends(sent, n=2) for sent in text))\n",
    "\n",
    "print('text',text)\n",
    "# koristimo pipeline u kojem su train i vocab generatori\n",
    "print('train',list(list(train)[0]))\n",
    "print('vocab',list(vocab))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 2 ngram orders and 33 ngrams>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0000000000000004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f'],['a','f','e']]\n",
    "test = [('a', 'b'), ('c', 'd')]\n",
    "\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train, vocab = padded_everygram_pipeline(2, text)\n",
    "\n",
    "\n",
    "from nltk.lm import MLE\n",
    "lm = MLE(2)\n",
    "len(lm.vocab)\n",
    "\n",
    "lm.fit(train, vocab)\n",
    "len(lm.vocab)\n",
    "\n",
    "lm.vocab.lookup(text[0])\n",
    "print(lm.counts)\n",
    "\n",
    "# koliko puta se pojavilo 'a'\n",
    "lm.counts['a']\n",
    "\n",
    "# koliko se pouta pojavilo 'a b' kao bigram\n",
    "lm.counts[['a']]['b']\n",
    "\n",
    "# vjerojatnost pridružena modelom \n",
    "lm.score('a')\n",
    "\n",
    "# koliko puta se pojavio 'b' nakon 'a' kao bigram\n",
    "lm.score(\"b\", [\"a\"])\n",
    "\n",
    "lm.entropy(test)\n",
    "lm.perplexity(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Primjer s korpusom teksta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "ExecuteTime": {
     "end_time": "2023-11-07T13:21:17.406860490Z",
     "start_time": "2023-11-07T13:21:17.365852036Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare(corpora,split=0.7):    \n",
    "    dataset = open(corpora,'r').read()\n",
    "    #dataset = re.sub('\\n',dataset,'.')\n",
    "    sents = nltk.tokenize.sent_tokenize(dataset)\n",
    "    #pdb.set_trace()\n",
    "    random.shuffle(sents)\n",
    "    index = random.randint(0, int(split*len(sents)))\n",
    "    trainset, testset = sents[index:], sents[:index]\n",
    "    \n",
    "    # store training set\n",
    "    with open('data/train.txt','w') as train:\n",
    "        for sent in trainset:\n",
    "            train.write(sent)\n",
    "            train.write('\\n')\n",
    "        \n",
    "    # store test set\n",
    "    with open('data/test.txt','w') as test:\n",
    "        for sent in testset: \n",
    "            test.write(sent)\n",
    "            test.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "ExecuteTime": {
     "end_time": "2023-11-07T13:21:36.619535842Z",
     "start_time": "2023-11-07T13:21:36.583019402Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/lektira/werther.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/lektira/werther.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m, in \u001B[0;36mprepare\u001B[0;34m(corpora, split)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprepare\u001B[39m(corpora,split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.7\u001B[39m):    \n\u001B[0;32m----> 2\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcorpora\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m#dataset = re.sub('\\n',dataset,'.')\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     sents \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mtokenize\u001B[38;5;241m.\u001B[39msent_tokenize(dataset)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    284\u001B[0m     )\n\u001B[0;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/lektira/werther.txt'"
     ]
    }
   ],
   "source": [
    "prepare('data/lektira/werther.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rado', 'ti', 'priznajem', '(', 'jer', 'znam', 'što', 'bi', 'mi', 'rekao', 'na', 'to', ')', 'da', 'su', 'najsretniji', 'oni', 'koji', ',', 'kao', 'djeca', ',', 'žive', 'od', 'dana', 'u', 'dan', ',', 'vuku', 'sa', 'sobom', 'svoje', 'lutke', ',', 'svlače', 'ih', 'i', 'oblače', 'i', 's', 'velikim', 'se', 'respektom', 'kradu', 'oko', 'ladice', 'u', 'koju', 'je', 'mamica', 'zaključala', 'slatkiš', ',', 'a', 'kad', 'napokon', 'ujagme', 'ono', 'što', 'žele', ',', 'gutaju', 'punim', 'ustima', 'i', 'viču', ':', 'Još', '!'], ['*'], ...]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PlaintextCorpusReader('data/','train.txt').sents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Povučem', 'ih', 'nazad', 'kao', 'od', 'vatre', ',', 'a', 'neka', 'tajna', 'sila', 'vuče', 'me', 'opet', 'naprijed', '—', 'nesvjestica', 'me', 'spopada', 'u', 'svim', 'ćutilima', '.'], ['A', 'zašto', 'ne', 'bi', '?'], ...]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PlaintextCorpusReader('data/','test.txt').sents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_set = PlaintextCorpusReader('data/','train.txt').sents()\n",
    "test_set  = PlaintextCorpusReader('data/','test.txt').sents()\n",
    "\n",
    "# ngrams\n",
    "nn = 2\n",
    "       \n",
    "# normaliziraj tokene\n",
    "train_set = [[token.lower() for token in sent] for sent in train_set ]\n",
    "test_set  =  [[token.lower() for token in sent] for sent in test_set ]\n",
    "\n",
    "test = [list(ngrams(sent,nn)) for sent in test_set][0]\n",
    "\n",
    "\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train, vocab = padded_everygram_pipeline(nn, train_set)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rado',\n",
       " 'ti',\n",
       " 'priznajem',\n",
       " '(',\n",
       " 'jer',\n",
       " 'znam',\n",
       " 'što',\n",
       " 'bi',\n",
       " 'mi',\n",
       " 'rekao',\n",
       " 'na',\n",
       " 'to',\n",
       " ')',\n",
       " 'da',\n",
       " 'su',\n",
       " 'najsretniji',\n",
       " 'oni',\n",
       " 'koji',\n",
       " ',',\n",
       " 'kao',\n",
       " 'djeca',\n",
       " ',',\n",
       " 'žive',\n",
       " 'od',\n",
       " 'dana',\n",
       " 'u',\n",
       " 'dan',\n",
       " ',',\n",
       " 'vuku',\n",
       " 'sa',\n",
       " 'sobom',\n",
       " 'svoje',\n",
       " 'lutke',\n",
       " ',',\n",
       " 'svlače',\n",
       " 'ih',\n",
       " 'i',\n",
       " 'oblače',\n",
       " 'i',\n",
       " 's',\n",
       " 'velikim',\n",
       " 'se',\n",
       " 'respektom',\n",
       " 'kradu',\n",
       " 'oko',\n",
       " 'ladice',\n",
       " 'u',\n",
       " 'koju',\n",
       " 'je',\n",
       " 'mamica',\n",
       " 'zaključala',\n",
       " 'slatkiš',\n",
       " ',',\n",
       " 'a',\n",
       " 'kad',\n",
       " 'napokon',\n",
       " 'ujagme',\n",
       " 'ono',\n",
       " 'što',\n",
       " 'žele',\n",
       " ',',\n",
       " 'gutaju',\n",
       " 'punim',\n",
       " 'ustima',\n",
       " 'i',\n",
       " 'viču',\n",
       " ':',\n",
       " 'još',\n",
       " '!']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['povučem',\n",
       " 'ih',\n",
       " 'nazad',\n",
       " 'kao',\n",
       " 'od',\n",
       " 'vatre',\n",
       " ',',\n",
       " 'a',\n",
       " 'neka',\n",
       " 'tajna',\n",
       " 'sila',\n",
       " 'vuče',\n",
       " 'me',\n",
       " 'opet',\n",
       " 'naprijed',\n",
       " '—',\n",
       " 'nesvjestica',\n",
       " 'me',\n",
       " 'spopada',\n",
       " 'u',\n",
       " 'svim',\n",
       " 'ćutilima',\n",
       " '.']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]\n",
    "test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Treniranje primjera iz vlastitog korpusa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.lm.vocabulary.Vocabulary at 0x7fba05671fa0>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10091"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 2 ngram orders and 100968 ngrams>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bio',)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12.833666754980955"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7299.929192712028"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['sila',\n",
       " ':',\n",
       " 'prisegao',\n",
       " 'sam',\n",
       " 'portret',\n",
       " 'započeo',\n",
       " 'triput',\n",
       " 'sam',\n",
       " 'već',\n",
       " 'se']"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.lm import MLE, Laplace\n",
    "lm = MLE(nn)\n",
    "#lm = Laplace(nn)\n",
    "lm.vocab\n",
    "\n",
    "# velicina n-grama u modelu\n",
    "print(lm.order)\n",
    "# treniraj model\n",
    "lm.fit(train, vocab)\n",
    "# nova velicina vokabulara\n",
    "len(lm.vocab)\n",
    "# velicine\n",
    "print(lm.counts)\n",
    "\n",
    "lm.vocab.lookup('bio'), \n",
    "lm.counts[['bio']]['je']\n",
    "\n",
    "\n",
    "lm.entropy(test)\n",
    "lm.perplexity(test)\n",
    "lm.generate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
